{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import arviz as az\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "v-4FT2HpHgS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from a CSV file\n",
        "df = pd.read_csv('./student_scores.csv')\n",
        "df\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "4aoheXQKKA5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "sns.histplot(df, x='Hours', bins=10, ax=ax[0])\n",
        "ax[0].set_title('Study Hours Hist')\n",
        "\n",
        "sns.histplot(df, x='Scores', bins=10, ax=ax[1])\n",
        "ax[1].set_title('Grades Score Hist')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-9M69tcFo2MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix for the data\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "InkJo2-JQosa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a joint plot to visualize the relationship between 'Hours' and 'Scores' colored by 'Bins'\n",
        "df['Bins'] = pd.cut(df['Hours'], bins=[0, 4, 7, float('inf')], labels=['low study', 'middle study', 'high study'])\n",
        "\n",
        "sns.jointplot(data=df, x=\"Hours\", y=\"Scores\", hue=\"Bins\")#, kind=\"kde\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PxFIywWRJR6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PyMC3 model\n",
        "basic_model = pm.Model()\n",
        "X = df['Hours'].values\n",
        "Y = df['Scores'].values\n",
        "\n",
        "# Define the Bayesian model\n",
        "with basic_model:\n",
        "\n",
        "    # Prior distributions for model parameters\n",
        "    beta_0 = pm.Gamma('beta_0', alpha=20, beta=1)\n",
        "    beta_1 = pm.Normal(\"beta_1\", mu=5, sigma=2.5)\n",
        "    sigma = pm.Gamma('sigma', alpha=2, beta=5)\n",
        "\n",
        "    # Linear regression model equation\n",
        "    mu = beta_0 + beta_1 * X\n",
        "\n",
        "    # Likelihood of the observed data\n",
        "    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=Y)\n",
        "\n",
        "    # Perform Bayesian inference using MCMC sampling\n",
        "    idata = pm.sample(return_inferencedata=True, draws=50000, tune=50000, chains=3)"
      ],
      "metadata": {
        "id": "aoaQo1GSQEEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idata"
      ],
      "metadata": {
        "id": "dmLEaSP6TWBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot trace plots for the model parameters\n",
        "pm.plot_trace(idata, compact=True)\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "56aXsuwHVSfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(idata, round_to=3)"
      ],
      "metadata": {
        "id": "S_w8E17NT7Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and display mean values of specific model parameters\n",
        "mean_beta1, mean_beta0, mean_sigma = az.summary(idata, round_to=3)['mean'].values"
      ],
      "metadata": {
        "id": "BTCx60smFmpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the median value for parameter 'beta_0' from the posterior samples\n",
        "param_name = 'beta_0'\n",
        "posterior_samples = idata.posterior[param_name].values.flatten()\n",
        "median_value_b0 = np.median(posterior_samples)\n",
        "print(f\"Median value for parameter '{param_name}': {median_value_b0}\")"
      ],
      "metadata": {
        "id": "5_wuqiYin4Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the median value for parameter 'beta_1' from the posterior samples\n",
        "param_name = 'beta_1'\n",
        "posterior_samples = idata.posterior[param_name].values.flatten()\n",
        "median_value_b1 = np.median(posterior_samples)\n",
        "print(f\"Median value for parameter '{param_name}': {median_value_b1}\")"
      ],
      "metadata": {
        "id": "YclIZYBnoA-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the median value for parameter 'sigma' from the posterior samples\n",
        "param_name = 'sigma'\n",
        "posterior_samples = idata.posterior[param_name].values.flatten()\n",
        "median_value_sigma = np.median(posterior_samples)\n",
        "print(f\"Median value for parameter '{param_name}': {median_value_sigma}\")"
      ],
      "metadata": {
        "id": "77g076ONoBWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot posterior distributions for all model parameters\n",
        "az.plot_posterior(idata)"
      ],
      "metadata": {
        "id": "t2SV58P0r1-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot autocorrelation plots for all model parameters\n",
        "az.plot_autocorr(idata, max_lag=100, combined = True)\n",
        "plt.ylim(-1, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXQAoBMHUBnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract posterior samples for model parameters\n",
        "posterior_samples = idata.posterior\n",
        "beta_0_samples = posterior_samples['beta_0'].values\n",
        "beta_1_samples = posterior_samples['beta_1'].values\n",
        "sigma_samples = posterior_samples['sigma'].values\n",
        "\n",
        "# Calculate mean values for model parameters after burn-in phase\n",
        "beta_0_samples = beta_0_samples.mean(axis=0)[1000:10000]\n",
        "beta_1_samples = beta_1_samples.mean(axis=0)[1000:10000]\n",
        "sigma_samples = sigma_samples.mean(axis=0)[1000:10000]\n",
        "\n",
        "print(len(beta_0_samples))\n",
        "print(len(beta_1_samples))\n",
        "print(len(sigma_samples))"
      ],
      "metadata": {
        "id": "PiCdOUT007e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 100000\n",
        "X_range = np.linspace(0, 10, 100)\n",
        "\n",
        "predictions = np.zeros((n_samples, len(X_range)))\n",
        "\n",
        "\n",
        "indeces = np.array([k for k in range(len(sigma_samples)-1)])\n",
        "\n",
        "# Generating predictions using posterior samples\n",
        "for i in range(n_samples):\n",
        "\n",
        "    index = np.random.choice(indeces)\n",
        "\n",
        "    beta_0_sample = beta_0_samples[index]\n",
        "    beta_1_sample = beta_1_samples[index]\n",
        "    sigma_sample = sigma_samples[index]\n",
        "\n",
        "    # Generating predictions based on the Bayesian linear regression model\n",
        "    #y_sample = np.random.normal(loc=beta_0_sample + beta_1_sample * X_range, scale=sigma_sample)\n",
        "    y_sample = np.random.normal(loc=median_value_b0 + median_value_b1 * X_range, scale=median_value_sigma)\n",
        "    predictions[i, :] = y_sample\n",
        "\n",
        "# Calculate the mean prediction and 95% credibility interval\n",
        "mean_pred = predictions.mean(axis=0)\n",
        "lower_bound = np.percentile(predictions, 2.5, axis=0)\n",
        "upper_bound = np.percentile(predictions, 97.5, axis=0)\n",
        "\n",
        "\n",
        "# Plot the MLE regression line, data points, and Bayesian linear regression results\n",
        "slope, intercept, _, _, _ = stats.linregress(df['Hours'], df['Scores'])\n",
        "plt.plot(X_range, intercept + slope * X_range, color='red', label='MLE Regression')\n",
        "\n",
        "\n",
        "plt.scatter(df['Hours'], df['Scores'], color='blue', label='Data points')\n",
        "plt.plot(X_range, mean_pred, color='blue', label='Mean prediction')\n",
        "plt.fill_between(X_range, lower_bound, upper_bound, color='blue', alpha=0.1, label='95% credibility interval')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.ylim(0.5, 99)\n",
        "plt.xlim(0.5, 9.5)\n",
        "plt.title('Bayesian Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pahQrSiXBNzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling 100000 values from the Bayesian model and computing the 90% interval of the prediction\n",
        "n_samples = 100000\n",
        "X = 6.5\n",
        "\n",
        "predictions = np.random.normal(loc=median_value_b0 + median_value_b1 * X, scale=median_value_sigma, size=n_samples)\n",
        "\n",
        "pd.DataFrame(predictions).hist(bins=100)"
      ],
      "metadata": {
        "id": "ejmmqebXx7v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(predictions).quantile(0.95)"
      ],
      "metadata": {
        "id": "d_w6zi24x7t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(predictions).quantile(0.05)"
      ],
      "metadata": {
        "id": "8w6LrZuix7rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.mean()"
      ],
      "metadata": {
        "id": "EkOuasLpx7np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "repeating the same process with non-informative priors"
      ],
      "metadata": {
        "id": "kq8avyD8sKqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uninf_model = pm.Model()\n",
        "X = df['Hours'].values\n",
        "Y = df['Scores'].values\n",
        "\n",
        "with uninf_model:\n",
        "\n",
        "    beta_0 = pm.Uniform('beta_0', lower=0, upper=100)\n",
        "    beta_1 = pm.Normal(\"beta_1\", mu=0, sigma=33)\n",
        "    sigma = pm.Uniform('sigma', lower=0, upper=100)\n",
        "\n",
        "    mu = beta_0 + beta_1 * X\n",
        "\n",
        "    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=Y)\n",
        "\n",
        "    idata = pm.sample(return_inferencedata=True, draws=100000, tune=100000, chains=3)\n"
      ],
      "metadata": {
        "id": "C6Czya2UY_Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.plot_trace(idata, compact=True)\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6uFeJbq5ZuZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_autocorr(idata, max_lag=100, combined = True)\n",
        "plt.ylim(-1, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5QclMP0Y_HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(idata, round_to=3)"
      ],
      "metadata": {
        "id": "CFnJ_5GYdPC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_beta1, mean_beta0, mean_sigma = az.summary(idata, round_to=3)['mean'].values"
      ],
      "metadata": {
        "id": "snM_CT8GrIjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior_samples = idata.posterior\n",
        "beta_0_samples = posterior_samples['beta_0'].values\n",
        "beta_1_samples = posterior_samples['beta_1'].values\n",
        "sigma_samples = posterior_samples['sigma'].values\n",
        "\n",
        "beta_0_samples = beta_0_samples.mean(axis=0)[1000:10000]\n",
        "beta_1_samples = beta_1_samples.mean(axis=0)[1000:10000]\n",
        "sigma_samples = sigma_samples.mean(axis=0)[1000:10000]\n",
        "\n",
        "print(len(beta_0_samples))\n",
        "print(len(beta_1_samples))\n",
        "print(len(sigma_samples))"
      ],
      "metadata": {
        "id": "53sRm4mHdIl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 100000\n",
        "X_range = np.linspace(0, 10, 100)\n",
        "\n",
        "predictions = np.zeros((n_samples, len(X_range)))\n",
        "\n",
        "\n",
        "indeces = np.array([k for k in range(len(sigma_samples)-1)])\n",
        "for i in range(n_samples):\n",
        "\n",
        "    index = np.random.choice(indeces)\n",
        "\n",
        "    beta_0_sample = beta_0_samples[index]\n",
        "    beta_1_sample = beta_1_samples[index]\n",
        "    sigma_sample = sigma_samples[index]\n",
        "\n",
        "    #y_sample = np.random.normal(loc=beta_0_sample + beta_1_sample * X_range, scale=sigma_sample)\n",
        "    y_sample = np.random.normal(loc=mean_beta0 + mean_beta1 * X_range, scale=mean_sigma)\n",
        "    predictions[i, :] = y_sample\n",
        "\n",
        "mean_pred = predictions.mean(axis=0)\n",
        "lower_bound = np.percentile(predictions, 2.5, axis=0)\n",
        "upper_bound = np.percentile(predictions, 97.5, axis=0)\n",
        "\n",
        "slope, intercept, _, _, _ = stats.linregress(df['Hours'], df['Scores'])\n",
        "plt.plot(X_range, intercept + slope * X_range, color='red', label='MLE Regression')\n",
        "\n",
        "\n",
        "plt.scatter(df['Hours'], df['Scores'], color='blue', label='Data points')\n",
        "plt.plot(X_range, mean_pred, color='blue', label='Mean prediction')\n",
        "plt.fill_between(X_range, lower_bound, upper_bound, color='blue', alpha=0.1, label='95% credibility interval')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.ylim(0.5, 99)\n",
        "plt.xlim(0.5, 9.5)\n",
        "plt.title('Bayesian Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZDBemzrHY_Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_model = pm.Model()\n",
        "X = df['Hours'].values\n",
        "Y = df['Scores'].values\n",
        "\n",
        "with bad_model:\n",
        "\n",
        "    beta_0 = pm.Gamma('beta_0', alpha=50, beta=0.1)\n",
        "    beta_1 = pm.Normal(\"beta_1\", mu=0, sigma=1)\n",
        "    sigma = pm.Gamma('sigma', alpha=1, beta=2)\n",
        "\n",
        "    mu = beta_0 + beta_1 * X\n",
        "\n",
        "    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=Y)\n",
        "\n",
        "    idata = pm.sample(return_inferencedata=True, draws=50000, tune=50000, chains=3)\n"
      ],
      "metadata": {
        "id": "05afgchCkupI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.plot_trace(idata, compact=True)\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JAjE3ULAog6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_autocorr(idata, max_lag=100, combined = True)\n",
        "plt.ylim(-1, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nBsYurC8okWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.summary(idata, round_to=3)"
      ],
      "metadata": {
        "id": "keiLN-PWom3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_beta1, mean_beta0, mean_sigma = az.summary(idata, round_to=3)['mean'].values"
      ],
      "metadata": {
        "id": "fKBY4o5DqzzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posterior_samples = idata.posterior\n",
        "beta_0_samples = posterior_samples['beta_0'].values\n",
        "beta_1_samples = posterior_samples['beta_1'].values\n",
        "sigma_samples = posterior_samples['sigma'].values\n",
        "\n",
        "beta_0_samples = beta_0_samples.mean(axis=0)[1000:10000]\n",
        "beta_1_samples = beta_1_samples.mean(axis=0)[1000:10000]\n",
        "sigma_samples = sigma_samples.mean(axis=0)[1000:10000]\n",
        "\n",
        "print(len(beta_0_samples))\n",
        "print(len(beta_1_samples))\n",
        "print(len(sigma_samples))"
      ],
      "metadata": {
        "id": "uQzpUL03ooeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 100000\n",
        "X_range = np.linspace(0, 10, 100)\n",
        "\n",
        "predictions = np.zeros((n_samples, len(X_range)))\n",
        "\n",
        "\n",
        "indeces = np.array([k for k in range(len(sigma_samples)-1)])\n",
        "for i in range(n_samples):\n",
        "\n",
        "    index = np.random.choice(indeces)\n",
        "\n",
        "    beta_0_sample = beta_0_samples[index]\n",
        "    beta_1_sample = beta_1_samples[index]\n",
        "    sigma_sample = sigma_samples[index]\n",
        "\n",
        "    #y_sample = np.random.normal(loc=beta_0_sample + beta_1_sample * X_range, scale=sigma_sample)\n",
        "    y_sample = np.random.normal(loc=mean_beta0 + mean_beta1 * X_range, scale=mean_sigma\t)\n",
        "    predictions[i, :] = y_sample\n",
        "\n",
        "mean_pred = predictions.mean(axis=0)\n",
        "lower_bound = np.percentile(predictions, 2.5, axis=0)\n",
        "upper_bound = np.percentile(predictions, 97.5, axis=0)\n",
        "\n",
        "slope, intercept, _, _, _ = stats.linregress(df['Hours'], df['Scores'])\n",
        "plt.plot(X_range, intercept + slope * X_range, color='red', label='MLE Regression')\n",
        "\n",
        "\n",
        "plt.scatter(df['Hours'], df['Scores'], color='blue', label='Data points')\n",
        "plt.plot(X_range, mean_pred, color='blue', label='Mean prediction')\n",
        "plt.fill_between(X_range, lower_bound, upper_bound, color='blue', alpha=0.1, label='95% credibility interval')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.ylim(0.5, 99)\n",
        "plt.xlim(0.5, 9.5)\n",
        "plt.title('Bayesian Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oGw_zNrGopue"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}